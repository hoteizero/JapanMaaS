# .github/workflows/data_sync.yml

name: MaaS Data Synchronization (ODPT to Supabase)

# 毎日午前3時 (UTC) に実行するスケジュールを設定
# 日本時間 (JST) の午前3時に実行したい場合は、UTCの午後6時 (18:00) に設定します。
on:
  schedule:
    # 毎日午前 3:00 (JST) = 毎日午後 6:00 (UTC) に実行
    - cron: '0 18 * * *'
  # 手動実行 (テスト用)
  workflow_dispatch:

jobs:
  sync_data:
    runs-on: ubuntu-latest
    
    # Supabase接続情報やAPIキーをGitHub Secretsから取得
    env:
      SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
      ODPT_API_KEY: ${{ secrets.ODPT_API_KEY }}

    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v4

      - name: 2. Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # スクリプトで指定したバージョンに合わせる

      - name: 3. Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/requirements.txt
          # psutil は PostgreSQL への接続に役立つ場合があるため、インストール
          sudo apt-get install postgresql-client -y

      - name: 4. Execute Data Processor (Python + DuckDB)
        id: process
        run: |
          # Pythonスクリプトを実行し、 odpt データを加工して data_insert.sql を生成
          python scripts/odpt_to_postgres_extended.py
        env:
          # Pythonスクリプト内で環境変数として利用
          ODPT_API_KEY: ${{ secrets.ODPT_API_KEY }}
          # 必要に応じて、事業者のマッピングファイルパスなどを指定

      - name: 5. Execute SQL on Supabase (PostgreSQL)
        # 生成された SQL ファイルを Supabase に投入
        # 認証情報 (SUPABASE_DB_URL) は環境変数として渡されます
        run: |
          echo "Generated SQL file content:"
          cat data_insert.sql
          
          # psql コマンドを使用してデータベースに接続し、SQLファイルを実行
          # SUPABASE_DB_URL の形式は postgres://user:password@host:port/database
          psql "$SUPABASE_DB_URL" -f data_insert.sql
        env:
          SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
          
      - name: 6. Cleanup (Optional: Remove sensitive SQL file)
        run: rm data_insert.sql
